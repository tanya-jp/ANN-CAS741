\documentclass[12pt, titlepage]{article}

\usepackage{amsmath, mathtools}

\usepackage[round]{natbib}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{colortbl}
\usepackage{xr}
\usepackage{hyperref}
\usepackage{longtable}
\usepackage{xfrac}
\usepackage{tabularx}
\usepackage{float}
\usepackage{siunitx}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage[section]{placeins}
\usepackage{caption}
\usepackage{fullpage}

\hypersetup{
bookmarks=true,     % show bookmarks bar?
colorlinks=true,       % false: boxed links; true: colored links
linkcolor=red,          % color of internal links (change box color with linkbordercolor)
citecolor=blue,      % color of links to bibliography
filecolor=magenta,  % color of file links
urlcolor=cyan          % color of external links
}

\usepackage{array}

\externaldocument{../../SRS/SRS}

\input{../../Comments}
\input{../../Common}

\def\code#1{\texttt{#1}}

\begin{document}

\title{Module Interface Specification for ANN (Artificial Neural Network)}

\author{Tanya Djavehrpour}

\date{\today}

\maketitle

\pagenumbering{roman}

\section{Revision History}

\begin{tabularx}{\textwidth}{p{3cm}p{2cm}X}
\toprule {\bf Date} & {\bf Version} & {\bf Notes}\\
\midrule
Mar. 19, 2024 & 1.0 & Initial Draft\\
Apr. 12, 2024 & 1.1 & Modification According to Implementation\\
% Date 2 & 1.1 & Notes\\
\bottomrule
\end{tabularx}

~\newpage

\section{Symbols, Abbreviations and Acronyms}

See SRS Documentation \cite{SRS} at \href{https://github.com/tanya-jp/ANN-CAS741/blob/main/docs/SRS/SRS.pdf}{HERE}.
% \wss{Also add any additional symbols, abbreviations or acronyms}

\newpage

\tableofcontents

\newpage

\pagenumbering{arabic}

\section{Introduction}

The following document details the Module Interface Specifications for
ANN (Artificial Neural Network). This document specifies how every module 
is interfacing with every other parts.

Complementary documents include the System Requirement Specifications 
(\href{https://github.com/tanya-jp/ANN-CAS741/blob/main/docs/SRS/SRS.pdf}{SRS}) \cite{SRS}
and Module Guide (\href{https://github.com/tanya-jp/ANN-CAS741/blob/main/docs/Design/SoftArchitecture/MG.pdf}{MG}) \cite{MG}.  
The full documentation and implementation can be
found at \href{https://github.com/tanya-jp/ANN-CAS741/tree/main}{Github repository for ANN}.

\section{Notation}

% \wss{You should describe your notation.  You can use what is below as
%   a starting point.}

The structure of the MIS for modules comes from \citet{HoffmanAndStrooper1995},
with the addition that template modules have been adapted from
\cite{GhezziEtAl2003}.  The mathematical notation comes from Chapter 3 of
\citet{HoffmanAndStrooper1995}.  For instance, the symbol := is used for a
multiple assignment statement and conditional rules follow the form $(c_1
\Rightarrow r_1 | c_2 \Rightarrow r_2 | ... | c_n \Rightarrow r_n )$.

The following table summarizes the primitive data types used by ANN. 

\begin{center}
\renewcommand{\arraystretch}{1.2}
\noindent 
\begin{tabular}{l l p{7.5cm}} 
\toprule 
\textbf{Data Type} & \textbf{Notation} & \textbf{Description}\\ 
\midrule
1D array & $\mathbf{A}_{i}$ & A linear sequence of elements\\
2D matrix & $\mathbf{M}_{ij}$ &  A collection of elements arranged in rows and columns\\
3D matrix & $\mathbf{M}_{ijk}$ & A structure composed of elements arranged in a grid with three dimensions\\ 
boolean & $bool$ & True or False\\
dictionary & $dict$ & A dictionary to store data as keys and values\\
string & $str$ & A sequence of characters\\
character & char & a single symbol or digit\\
integer & $\mathbb{Z}$ & a number without a fractional component in (-$\infty$, $\infty$) \\
positive Integer & $\mathbf{Z}_{+}$ & a number without a fractional component in ($0$, $\infty$) \\
natural number & $\mathbb{N}$ & a number without a fractional component in [1, $\infty$) \\
real & $\mathbb{R}$ & any number in (-$\infty$, $\infty$)\\
\bottomrule
\end{tabular} 
\end{center}

\noindent
The specification of ANN uses some derived data types: sequences, strings, and
tuples. Sequences are lists filled with elements of the same data type. Strings
are sequences of characters. Tuples contain a list of values, potentially of
different types. In addition, ANN uses functions, which
are defined by the data types of their inputs and outputs. Local functions are
described by giving their type signature followed by their specification.

\section{Module Decomposition}

The following table is taken directly from the Module Guide \cite{MG} document for this project.

\begin{table}[h!]
\centering
\begin{tabular}{p{0.3\textwidth} p{0.6\textwidth}}
\toprule
\textbf{Level 1} & \textbf{Level 2}\\
\midrule

{Hardware-Hiding} & ~ \\
\midrule

\multirow{7}{0.3\textwidth}{Behaviour-Hiding} &ANN Control Module\\
&Saved ANN Model Module\\
&Output Module\\
&Input Classifier Module\\
&Input Image Module\\
&Training Model Module\\
% &Feedback Module\\
\midrule

\multirow{3}{0.3\textwidth}{Software Decision} &Input Preparing and Preprocessing Module\\
&Data Preparing and Preprocessing Module\\
&Training and Testing Module\\
% &Testing Module\\
\bottomrule

\end{tabular}
\caption{Module Hierarchy}
\label{TblMH}
\end{table}

\newpage
~\newpage

\section{MIS of ANN Control Module} \label{ACM} 
% \wss{Use labels for
%   cross-referencing}

% \wss{You can reference SRS labels, such as R\ref{R_Inputs}.}

% \wss{It is also possible to use \LaTeX for hypperlinks to external documents.}

\subsection{Module}
\code{main} 

% \wss{Short name for the module}

\subsection{Uses}
\begin{itemize}
  \item Hardware-Hiding Module  
  \item Saved ANN Model Module (\ref{SavedANN})
  \item Output Module (\ref{Output})
\end{itemize}


\subsection{Syntax}

\subsubsection{Exported Constants}
None.

\subsubsection{Exported Access Programs}

\begin{center}
\begin{tabular}{p{2cm} p{4cm} p{4cm} p{2cm}}
\hline
\textbf{Name} & \textbf{In} & \textbf{Out} & \textbf{Exceptions} \\
\hline
\code{main} & - & - & - \\
\hline
\end{tabular}
\end{center}

\subsection{Semantics}

\subsubsection{State Variables}
None.
% \wss{Not all modules will have state variables.  State variables give the module
%   a memory.}

\subsubsection{Environment Variables}
None.

% \wss{This section is not necessary for all modules.  Its purpose is to capture
%   when the module has external interaction with the environment, such as for a
%   device driver, screen interface, keyboard, file, etc.}

\subsubsection{Assumptions}
\begin{itemize}
  \item The ANN Control Module assumes that the Hardware-Hiding Module, Saved ANN Model Module, and Output Module are implemented 
  according to their specifications. However, it does include error handling to manage unexpected behaviors or failures in these modules.
  \item The system environment (operating system, hardware) is assumed to be stable. 
  Also, essential libraries and dependencies are presumed to be correctly installed and configured.
\end{itemize}


% \wss{Try to minimize assumptions and anticipate programmer errors via
%   exceptions, but for practical purposes assumptions are sometimes appropriate.}

\subsubsection{Access Routine Semantics}

\noindent main():
\begin{itemize}
  \item transition: Initializes the program.
  % \item output: 
  % \item exception: 
\end{itemize}

Note: As the ANN Control Module mainly serves as a coordinator between different modules 
without maintaining its own state or producing output, its primary function is to ensure 
the correct sequence of operations and interactions between these modules. It relies on 
the robustness of the called modules' error handling.


% \wss{A module without environment variables or state variables is unlikely to
%   have a state transition.  In this case a state transition can only occur if
%   the module is changing the state of another module.}

% \wss{Modules rarely have both a transition and an output.  In most cases you
%   will have one or the other.}

\subsubsection{Local Functions}
None.

% \wss{As appropriate} \wss{These functions are for the purpose of specification.
%   They are not necessarily something that is going to be implemented
%   explicitly.  Even if they are implemented, they are not exported; they only
%   have local scope.}

\newpage

\section{MIS of Saved ANN Model Module} \label{SavedANN} 

\subsection{Module}
\code{model} 

\subsection{Uses}
\begin{itemize}
  \item Hardware-Hiding Module  
  \item Training and Testing Module (\ref{Train})
\end{itemize}


\subsection{Syntax}

\subsubsection{Exported Constants}
None.

\subsubsection{Exported Access Programs}

\begin{center}
\begin{tabular}{p{5cm} p{4cm} p{4cm} p{3.5cm}}
\hline
\textbf{Name} & \textbf{In} & \textbf{Out} & \textbf{Exceptions} \\
\hline
\code{save\_model} & - & $bool$ & \code{PermissionError} \\
\code{load\_trained\_classifier} & $\mathbf{A}_{i}$, $str$ & $\mathbf{Z}_{+}$ & - \\
\hline
\end{tabular}
\end{center}

\subsection{Semantics}

\subsubsection{State Variables}
None.
% \begin{itemize}
%   \item \code{modelData}: Data structure holding the current ANN model's data. 
% This is an array including weights and biases.
% \end{itemize}

\subsubsection{Environment Variables}
None.
% \code{modelFile}: A file on the file system where the ANN model data is saved and 
% from where it is loaded.

\subsubsection{Assumptions}
None.

\subsubsection{Access Routine Semantics}

\noindent \code{save\_model}():
\begin{itemize}
  \item transition: Writes the current state of the ANN model (weights and biases) to a \code{.npy} file 
  as a $dict$.
  \item output: Returns \code{True} if model is saved successfully.
  \item exception: Raises \code{PermissionError} if the module lacks the necessary permissions to write to \code{modelFile}. 
  It may also raise an IOError if there are issues with the file system, such as insufficient storage space.
\end{itemize}

\noindent \code{load\_trained\_classifier}(\code{input\_image, model\_name}):
\begin{itemize}
  \item transition: Loads a trained classifier and uses it to predict a class for the input image. 
  \item output: The predicted class as $\mathbf{Z}_{+}$, based on the vector of input image and 
  name of the saved model.
  \item exception: None.
\end{itemize}


\subsubsection{Local Functions}
\noindent \code{load\_model}(\code{file\_name}):
\begin{itemize}
  \item transition: Load model parameters from a specified code{.npy} file.
  \item output: The model parameters stored in the file as a $dict$.
  \item exception: Raises \code{FileNotFoundError} if \code{modelFile} does not exist or cannot be accessed. 
  Additionally, an exception may be raised for data corruption or format mismatch, indicating issues 
  with the integrity or compatibility of the stored model data.
\end{itemize}
\newpage

\section{MIS of Output Module} \label{Output} 

\subsection{Module}
\code{output} 

\subsection{Uses}
\begin{itemize}
  \item Hardware-Hiding Module  
  \item Input Classifier Module (\ref{In-class})
\end{itemize}


\subsection{Syntax}

\subsubsection{Exported Constants}
None.

\subsubsection{Exported Access Programs}

\begin{center}
\begin{tabular}{p{3cm} p{4cm} p{4cm} p{3cm}}
\hline
\textbf{Name} & \textbf{In} & \textbf{Out} & \textbf{Exceptions} \\
\hline
\code{set\_class\_name} & - & $str$ & - \\
\code{save\_feedback} & - & - &  -\\
\hline
\end{tabular}
\end{center}

\subsection{Semantics}

\subsubsection{State Variables}
\code{class\_name}: The $str$ as the name of the class to which the image has been classified.

\subsubsection{Environment Variables}
None.

\subsubsection{Assumptions}
None.

\subsubsection{Access Routine Semantics}

\noindent \code{set\_class\_name}():
\begin{itemize}
  \item transition: Determines the class name of an image using the Input Classifier Module (\ref{In-class}).
  \item output: he class name determined by the Input Classifier Module (\ref{In-class}).
  \item exception: None.
\end{itemize}

\noindent \code{save\_feedback}():
\begin{itemize}
  \item transition: ollects and saves user feedback on the classification result to a text file.
  \item output: None.
  \item exception: None.
\end{itemize}


\subsubsection{Local Functions}
\noindent \code{append\_to\_file}(\code{file\_path, sentence}):
\begin{itemize}
  \item transition: Appends a given feedback to a file and prints a success message or error message depending on 
  the outcome of the file operation.
  \item output: None.
  \item exception: Raises \code{FileNotFoundError} if the destination \code{.txt} file is not found. 
  \code{IOError} will be raised, if there is a problem with writing to the file. 
\end{itemize}

\newpage

\section{MIS of Input Classifier Module} \label{In-class} 

\subsection{Module}
\code{classifier} 

\subsection{Uses}
\begin{itemize}
  \item Hardware-Hiding Module  
  \item Saved ANN Module (\ref{SavedANN})
  \item Input Preparing and Preprocessing Module (\ref{In-prep})
\end{itemize}


\subsection{Syntax}

\subsubsection{Exported Constants}
None.

\subsubsection{Exported Access Programs}

\begin{center}
\begin{tabular}{p{3cm} p{4cm} p{4cm} p{2cm}}
\hline
\textbf{Name} & \textbf{In} & \textbf{Out} & \textbf{Exceptions} \\
\hline
\code{set\_image\_pixel} & - & - & - \\
\code{get\_class} & - & $str$&  -\\
\hline
\end{tabular}
\end{center}

\subsection{Semantics}

\subsubsection{State Variables}
\begin{itemize}
  \item \code{input\_image}: An array of input image's pixels after preprocessing.
  \item \code{class\_name}: The $str$ as the name of the class to which the image has been classified.
\end{itemize}

\subsubsection{Environment Variables}
None.

\subsubsection{Assumptions}
None.

\subsubsection{Access Routine Semantics}

\noindent \code{set\_image\_pixels}():
\begin{itemize}
  \item transition: Receives the array of input image from Input Preparing and Preprocessing Module (\ref{In-prep}) 
  and saves in \code{input\_image}.
  \item output: None.
  \item exception: None.
\end{itemize}

\noindent \code{get\_class}():
\begin{itemize}
  \item transition: Classifies the preprocessed image using a pretrained model from (\ref{SavedANN}) and 
                    maps the output to a class name.
  \item output: The class of the input image.
  \item exception: None.
\end{itemize}

\newpage

\section{MIS of Input Image Module} \label{In-set} 

\subsection{Module}
\code{input} 

\subsection{Uses}
\begin{itemize}
  \item Hardware-Hiding Module  
\end{itemize}


\subsection{Syntax}

\subsubsection{Exported Constants}
\begin{itemize}
  \item \code{HEIGHT}: A value ($\mathbf{Z}_{+}$) describing acceptable height of input image 
  (currently 32).
  \item \code{WIDTH}: A value ($\mathbf{Z}_{+}$) describing acceptable width of input image
  (currently 32).
  \item \code{IMAGE\_FORMAT}: A list of strings ($str$) of acceptable types of input image 
  (currently PNG and JPEG).
\end{itemize}

\subsubsection{Exported Access Programs}

\begin{center}
\begin{tabular}{p{3.5cm} p{4cm} p{4cm} p{4cm}}
\hline
\textbf{Name} & \textbf{In} & \textbf{Out} & \textbf{Exceptions} \\
\hline
\code{set\_image} & - & $\mathbf{M}_{ijk}$ & \code{FileNotFoundError, InvalidSize, InvalidFormat} \\
\hline
\end{tabular}
\end{center}

\subsection{Semantics}

\subsubsection{State Variables}
None.

\subsubsection{Environment Variables}
None.

\subsubsection{Assumptions}
None.

\subsubsection{Access Routine Semantics}

\noindent \code{set\_image}():
\begin{itemize}
  \item transition: Receives the input image from end user and returns its matrix as \code{inputImage}.
  \item output: None.
  \item exception: Raises \code{FileNotFoundError} if \code{inputImagePath} does not exist or cannot be accessed. 
  Also, \code{InvalidSize} is raised when the size of input image in not compatible with \code{HEIGHT} or 
  \code{WIDTH}. Additionally, \code{InvalidFormat} is thrown if the input image's format is 
  not compatible with \code{IMAGE\_FORMAT}.
\end{itemize}

\subsubsection{Local Functions}
None.

\newpage

\section{MIS of Training Model Module} \label{Train-Model} 

\subsection{Module}
\code{training\_model} 

\subsection{Uses}
\begin{itemize}
  \item Data Preparing and Preprocessing Module (\ref{Data})
\end{itemize}


\subsection{Syntax}
\subsubsection{Exported Constants}
\begin{itemize}
  \item \code{LAYERS\_NUMBER}: A value ($\mathbf{Z}_{+}$) describing the number of 
  neural network's layers.
  \item \code{LAYERS\_NEURONS}: An array including each layer's number of neurons.
\end{itemize}

\subsubsection{Exported Access Programs}

\begin{center}
\begin{tabular}{p{3.5cm} p{4cm} p{4cm} p{3.5cm}}
\hline
\textbf{Name} & \textbf{In} & \textbf{Out} & \textbf{Exceptions} \\
\hline
\code{create\_gradients} & - & $\mathbf{A}_{i}$ & - \\
\hline
\end{tabular}
\end{center}

\subsection{Semantics}

\subsubsection{State Variables}
None.

\subsubsection{Environment Variables}
None.

\subsubsection{Assumptions}
None.

\subsubsection{Access Routine Semantics}

\noindent \code{create\_gradients}():
\begin{itemize}
  \item transition: Creates zero arrays for all needed gradients based on the 
  \code{LAYERS\_NUMBER} and \code{LAYERS\_NEURONS}.
  \item output: All gradients' zero vector ($\mathbf{A}_{i}$)
  \item exception: None.
\end{itemize}

\subsubsection{Local Functions}
None.

\newpage

\section{Input Preparing and Preprocessing Module} \label{In-prep} 

\subsection{Module}
\code{input\_prep} 

\subsection{Uses}
Data Preparing and Preprocessing Module (\ref{Data})\\
Input Image Module (\ref{In-set}) 

\subsection{Syntax}
\subsubsection{Exported Constants}
None.

\subsubsection{Exported Access Programs}

\begin{center}
\begin{tabular}{p{3.5cm} p{4cm} p{4cm} p{2cm}}
\hline
\textbf{Name} & \textbf{In} & \textbf{Out} & \textbf{Exceptions} \\
\hline
\code{get\_input} & - & $\mathbf{A}_{i}$ & - \\
\hline
\end{tabular}
\end{center}

\subsection{Semantics}

\subsubsection{State Variables}
\begin{itemize}
  \item \code{input\_image}: Incling input image pixels.
\end{itemize}

\subsubsection{Environment Variables}
None.

\subsubsection{Assumptions}
None.

\subsubsection{Access Routine Semantics}

\noindent \code{input\_prep}():
\begin{itemize}
  \item transition: Prepares and preprocess the input image to change it 
  the way model can use it to predicts the class.
  \item output: an $\mathbf{A}_{i}$ including prepared and preprocessed input image.
  \item exception: None.
\end{itemize}

\subsubsection{Local Functions}
\begin{itemize}
  \item \code{set\_image\_pixels}():
  \begin{itemize}
    \item transition: Loads an image using the Input Image Module (\ref{In-set}).
    and store it in \code{input\_image}.
    \item output: None.
    \item exception: None.
  \end{itemize}

  \item \code{rgb2gray}():
  \begin{itemize}
    \item transition: Uses Data Preparing and Preprocessing Module (\ref{Data}) to convert 
    RGB data (\code{input\_image}) into grayscale to reduce the complexity. 
    \item output: None.
    \item exception: None.
  \end{itemize}
  \item \code{prep\_pixels}():
  \begin{itemize}
    \item transition: Normalizes grayscaled (\code{input\_image}) to change the range of data between 0 and 1, 
    using Data Preparing and Preprocessing Module (\ref{Data}).
    \item output: None.
    \item exception: None.
  \end{itemize}
  \item \code{flat\_data}():
  \begin{itemize}
    \item transition: Data is flatten since (\code{input\_image}) should be vectorized 
    with the size of 1024. 
    After grayscaling input image is a $\mathbf{M}_{ij}$. this should be an $\mathbf{A}_{i}$ to be used by implemented model.
    \item output: None.
    \item exception: None.
  \end{itemize}

\end{itemize}

\newpage

\section{Data Preparing and Preprocessing Module} \label{Data} 

\subsection{Module}
\code{data} 

\subsection{Uses}
None.

\subsection{Syntax}
\subsubsection{Exported Constants}
None.

\subsubsection{Exported Access Programs}

\begin{center}
\begin{tabular}{p{3.5cm} p{4cm} p{6cm} p{2cm}}
\hline
\textbf{Name} & \textbf{In} & \textbf{Out} & \textbf{Exceptions} \\
\hline
\code{get\_dataset} & - & [$\mathbf{M}_{ij}$, $\mathbf{A}_{i}$], [$\mathbf{M}_{ij}$, $\mathbf{A}_{i}$] & - \\
\code{rgb2gray} & [$\mathbf{M}_{ij}$], $bool$ & - & -\\
\code{prep\_pixels} & [$\mathbf{M}_{ij}$] & - & -\\
\hline
\end{tabular}
\end{center}

\subsection{Semantics}

\subsubsection{State Variables}
\begin{itemize}
  \item \code{train\_data}: Data structure holding train data images and their labels. 
  Since train images after processing are vectors ($\mathbf{A}_{i}$), a list of these images is 
  a matix ($\mathbf{M}_{ij}$). Alos, labels are saving in a vector ($\mathbf{A}_{i}$). 
  Consequently, this data structure is a list in [$\mathbf{M}_{ij}$, $\mathbf{A}_{i}$] format.
  \item \code{test\_data}: Data structure holding test data images and their labels. 
  Since test images after processing are vectors ($\mathbf{A}_{i}$), a list of these images is 
  a matix ($\mathbf{M}_{ij}$). Alos, labels are saving in a vector ($\mathbf{A}_{i}$). 
  Consequently, this data structure is a list in [$\mathbf{M}_{ij}$, $\mathbf{A}_{i}$] format.
  \item \code{train\_images}: A list incling traing data images.
  \item \code{test\_images}:  Alist incling test data images.
\end{itemize}

\subsubsection{Environment Variables}
None.

\subsubsection{Assumptions}
None.

\subsubsection{Access Routine Semantics}

\noindent \code{get\_dataset}():
\begin{itemize}
  \item transition: Processes and retrieve the training and testing datasets.
  \item output: \code{train\_data}, \code{test\_data}
  \item exception: None.
\end{itemize}

\noindent \code{rgb2gray}(images, input\_image):
\begin{itemize}
  \item transition: Converts RGB data into grayscale in order to reduce complexity. 
  First input is a numpy array representing one or more images in RGB format. 
  If a single image, it should be a $\mathbf{M}_{ijk}$ array 
  (height, width, color\_channels). If multiple images, it should be a 4D array 
  (number\_images, height, width, color\_channels).
  Second input as a $bool$. It is a flag to indicate if the provided 'images' 
  parameter is a single image (True) or a batch of images (False). Default is False.
  \item output: The transformed grayscale images. If 'images' was a 
  single image, the return is a $\mathbf{M}_{ij}$ (height, width).
  If 'images' was a batch of images, the return is a $\mathbf{M}_{ijk}$ 
  array (number\_images, height, width).
  \item exception: None.
\end{itemize}

\noindent \code{prep\_pixels}(images):
\begin{itemize}
  \item transition: Normalizes grayscaled images to change the range of data between 0 and 1.
  \item output: Normalized images.
  \item exception: None.
\end{itemize}

\subsubsection{Local Functions}
\begin{itemize}
  \item \code{save\_data}():
  \begin{itemize}
    \item transition: Downloads the file from Google Drive and saves it locally.
    \item output: None.
    \item exception: This function raises \code{UnableToDownload}, when there is 
    a problem with downloading or extracting data.
  \end{itemize}

  \item \code{load\_data}():
  \begin{itemize}
    \item transition: Loads \code{train\_data} and \code{test\_data}, ecnods the labels. 
    The dataset is load using \code{keras.datasets}.
    This function updates \code{train\_images} and \code{test\_images} as well. 
    \item output: None.
    \item exception: This function raises \code{UnableToDownload}, when there is 
    a problem with downloading or extracting data.
  \end{itemize}

  \item \code{flat\_data}(images):
  \begin{itemize}
    \item transition: Data is flatten since imagws should be vectorized with the size of 1024. 
    After grayscaling each image is a $\mathbf{M}_{ij}$. These images should be an $\mathbf{A}_{i}$ to be used in 
    training and testing process by implemented model.
    \item output: Flattened images.
    \item exception: None.
  \end{itemize}

  \item \code{shuffle\_data}(data, images):
  \begin{itemize}
    \item transition: Combines images with their corresponding labels, one-hot encodes the labels, 
    and then shuffles the combined data for randomness.
    \item output: \code{train\_data} and \code{test\_data}.
    \item exception: A tuple as [$\mathbf{M}_{ij}$, $\mathbf{A}_{i}$], 
    where each tuple contains a shuffled image and its label.
  \end{itemize}

\end{itemize}

\newpage

\section{MIS of Training and Testing Module} \label{Train} 
The details of fucntions using here are described in SRS document \cite{SRS}.
\subsection{Module}
\code{train\_and\_test} 

\subsection{Uses}
\begin{itemize}
  \item Training Model Module (\ref{Train-Model})
  \item Data Preparing and Preprocessing Module (\ref{Data})
\end{itemize}


\subsection{Syntax}
\subsubsection{Exported Constants} \label{Train-Const}
\begin{itemize}
  \item \code{BATCH\_SIZE}: The partition size of the dataset for each step of learning, 
  typically a power of two.
  \item \code{LEARNING\_RATE}: Speed at which the model learns; controls adjustments to the weights.
  \item \code{EPOCHS}: Total number of training cycles through the entire dataset.
\end{itemize}

\subsubsection{Exported Access Programs}

\begin{center}
\begin{tabular}{p{7cm} p{3cm} p{3cm} p{2cm}}
\hline
\textbf{Name} & \textbf{In} & \textbf{Out} & \textbf{Exceptions} \\
\hline
\code{train} &- & $dict$, $\mathbf{A}_{i}$, $\mathbf{Z}_{+}$, $\mathbf{Z}_{+}$  & -\\
\code{result} & $dict$, $\mathbf{A}_{i}$ & - & -\\
\code{calculate\_percentage\_of\_accuracy} & $\mathbf{M}_{ij}$, $dict$, $bool$ & - & -\\
                                           & or [$\mathbf{M}_{ijk}$, $\mathbf{M}_{i}$], $dict$, $bool$ & - & -\\
\hline
\end{tabular}
\end{center}

\subsection{Semantics}

\subsubsection{State Variables}
\begin{itemize}
  \item \code{layers}: Layers dimensions are defined based on the 
  model architecture and are saved in an $\mathbf{A}_{i}$ named layers.
\end{itemize}

\subsubsection{Environment Variables}
None.

\subsubsection{Assumptions}
None.

\subsubsection{Access Routine Semantics}

\noindent \code{train}():
\begin{itemize}
  \item transition: Trains the model based on constant variables defined in \ref{Train-Model}. 
  Gradient arrays and train data are needed for training. 
  The training process involves initializing parameters, performing forward and backward 
  passes for each batch, and updating the parameters using the computed gradients. The 
  process is repeated for a specified number of epochs.
  \item output: The final trained parameters, cost for each epoch, 
  start time, and end time of training.
  \item exception: None.
\end{itemize}

\noindent \code{result}(epochs\_costs, trained\_params):
\begin{itemize}
  \item transition: Displays the accuracy percentages for training and testing 
  datasets and plots the training cost over epochs.
  This method calculates and prints the accuracy on both the 
  training and testing datasets using the trained model parameters. 
  It also generates a plot of the training costs over epochs to 
  visually assess the model's learning progress.
  \item output: This method prints the accuracy percentages for 
  the training and test datasets to the console and
  displays a line plot of the training costs over 
  epochs, showing changes in cost with each epoch.
  \item exception: None.
\end{itemize}

\noindent \code{calculate\_percentage\_of\_accuracy}(data, parameters, input\_image = False):
\begin{itemize}
  \item transition: Calculates the accuracy of the neural network model on a given dataset or 
  finds the predicted class of an input image.
  Accuracy is determined by comparing the predicted labels against the actual labels and 
   calculating the percentage of correct predictions.
  \item output: Accuracy percentage if input\_image is \code{False}, or class index if \code{True}.
  \item exception: None.
\end{itemize}


\subsubsection{Local Functions}
\noindent \code{set\_layers}():
\begin{itemize}
  \item transition: \code{layers} is set based on Train Model Module (\ref{Train-Model}) 
  and the gradients.
  \item output: None.
  \item exception: None.
\end{itemize}

\begin{itemize}
  \item \code{sigmoid}(x):
  \begin{itemize}
    \item transition: Calculates sigmoid function for x, as the activation function.
    \item output: Sigmoid value of x. 
    \item exception: None.
  \end{itemize}

  \item \code{initialize\_parameters}(layers):
  \begin{itemize}
    \item transition: Allocates random normal weights ($\mathbf{M}_{ij}$) 
    and zero biases ($\mathbf{A}_{i}$) for each layer.
    \item output: Returns a dictionary (named \code{parameters}) 
    that the keys define weights or biases, and the values are allocated random numbers 
    to each of them.
    \item exception: None.
  \end{itemize}

  \item \code{compute\_cost}(predicted, actual):
  \begin{itemize}
    \item transition: Calculates the sum of the squared errors based on the 
    predicted and actual values.
    \item output: Returns the sum of the squared errors
    \item exception: None.
  \end{itemize}

  \item \code{feed\_forward}(predicted, parameters, layersNumb):
  \begin{itemize}
    \item transition: Calculates feedforwarding process as described in SRS \cite{SRS}. 
    This is done by using the predicted value of previous step, parameters and the number of layers, 
    \code{parameters} dictionary and the number of layers.
    \item output: Returns the new predicted value and a \code{cache} including new and old parameters.
    \item exception: None.
  \end{itemize}

  \item \code{extract\_parameters}(cache):
  \begin{itemize}
    \item transition: Extracts parameters saved during forwardfeeding from the cache, based on \code{layers},
    \code{parameters} dictionary and the number of layers.
    \item output: Returns extracted parameters.
    \item exception: None.
  \end{itemize}

  \item \code{backpropagation}(cache, predicted, actual, layers):
  \begin{itemize}
    \item transition: Calculates backpropagation process as described in SRS \cite{SRS} 
    to calculate gradients of wights and biases. 
    \item output: A dictionary as gradients that keys are labels of gradients to define weights or biases, 
    and values are gradients.
    \item exception: None.
  \end{itemize}

\end{itemize}

\newpage

\bibliographystyle {plainnat}
\bibliography {../../../refs/References}

\newpage

% \section{Appendix} \label{Appendix}

% \wss{Extra information if required}

% \section{Reflection}

% The information in this section will be used to evaluate the team members on the
% graduate attribute of Problem Analysis and Design.  Please answer the following questions:

% \begin{enumerate}
%   \item What are the limitations of your solution?  Put another way, given
%   unlimited resources, what could you do to make the project better? (LO\_ProbSolutions)
%   \item Give a brief overview of other design solutions you considered.  What
%   are the benefits and tradeoffs of those other designs compared with the chosen
%   design?  From all the potential options, why did you select the documented design?
%   (LO\_Explores)
% \end{enumerate}


\end{document}